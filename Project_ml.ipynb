{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import gensim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the reviews dataset. These are 194439 amazon reviews for cell phones and accessories taken from https://jmcauley.ucsd.edu/data/amazon/ Use the “reviewText” and “overall” fields from this file. The goal is to predict the rating given the review by modeling it as a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"Cell_Phones_and_Accessories_5.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 194439 rows and 9 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the “reviewText” and “overall” fields from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'] + data['summary'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewText', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  They look good and stick good! I just don't li...        4\n",
       "1  These stickers work like the review says they ...        5\n",
       "2  These are awesome and make my phone look so st...        5\n",
       "3  Item arrived in great time and was in perfect ...        4\n",
       "4  awesome! stays on, and looks great. can be use...        5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "#stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    return tokens\n",
    "\n",
    "data['processed_text'] = data['reviewText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>[look, good, stick, good, n't, like, rounded, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[sticker, work, like, review, say, stick, grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>[awesome, make, phone, look, stylish, used, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[item, arrived, great, time, perfect, conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>[awesome, stay, look, great, used, multiple, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [look, good, stick, good, n't, like, rounded, ...  \n",
       "1  [sticker, work, like, review, say, stick, grea...  \n",
       "2  [awesome, make, phone, look, stylish, used, on...  \n",
       "3  [item, arrived, great, time, perfect, conditio...  \n",
       "4  [awesome, stay, look, great, used, multiple, a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.overall = data.overall.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null reviews\n",
    "\n",
    "Looks like there are None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText        0\n",
       "overall           0\n",
       "processed_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =[]\n",
    "for text in data.processed_text:\n",
    "    tokens.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    108664\n",
       "4     39993\n",
       "3     21439\n",
       "1     13279\n",
       "2     11064\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tTake the first 70% dataset for train, next 10% for validation/development, and remaining 20% for test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194439, 3) (136107, 3) (19444, 3) (38888, 3)\n"
     ]
    }
   ],
   "source": [
    "train = data[0:floor(0.7*len(data))]\n",
    "validate = data[floor(0.7*len(data)):floor(0.8*len(data))]\n",
    "test = data[floor(0.8*len(data)):]\n",
    "\n",
    "print(data.shape, train.shape, validate.shape, test.shape)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    73942\n",
      "4    27955\n",
      "3    15843\n",
      "1    10141\n",
      "2     8226\n",
      "Name: overall, dtype: int64\n",
      "5    11035\n",
      "4     4072\n",
      "3     2123\n",
      "1     1175\n",
      "2     1039\n",
      "Name: overall, dtype: int64\n",
      "5    23687\n",
      "4     7966\n",
      "3     3473\n",
      "1     1963\n",
      "2     1799\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.overall.value_counts())\n",
    "print(validate.overall.value_counts())\n",
    "print(test.overall.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train[train.overall == 5]\n",
    "train1 = train1.sample(frac=0.45, replace=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95439, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[train.overall != 5]\n",
    "train = pd.concat([train, train1], ignore_index=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              reviewText  overall  \\\n",
      "0      They look good and stick good! I just don't li...        4   \n",
      "1      Item arrived in great time and was in perfect ...        4   \n",
      "2      These make using the home button easy. My daug...        3   \n",
      "3      it worked for the first week then it only char...        1   \n",
      "4      It worked great for the first couple of weeks ...        1   \n",
      "...                                                  ...      ...   \n",
      "95434  I have a long commute to work and wish not to ...        5   \n",
      "95435  I am super happy with this product.  I bought ...        5   \n",
      "95436  It fits my phone perfectly and It installed fl...        5   \n",
      "95437  I love my HTC  Evo, but battery life is an iss...        5   \n",
      "95438  It is not bulky and the way it stays on the ph...        5   \n",
      "\n",
      "                                          processed_text  \n",
      "0      [look, good, stick, good, n't, like, rounded, ...  \n",
      "1      [item, arrived, great, time, perfect, conditio...  \n",
      "2      [make, using, home, button, easy, daughter, li...  \n",
      "3      [worked, first, week, charge, phone, waste, mo...  \n",
      "4      [worked, great, first, couple, week, stopped, ...  \n",
      "...                                                  ...  \n",
      "95434  [long, commute, work, wish, hold, phone, got, ...  \n",
      "95435  [super, happy, product, bought, thought, going...  \n",
      "95436  [fit, phone, perfectly, installed, flawlessly,...  \n",
      "95437  [love, htc, evo, battery, life, issue, recentl...  \n",
      "95438  [bulky, way, stay, phone, pink, back, replace,...  \n",
      "\n",
      "[95439 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(train)\n",
    "del train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tTraditional machine learning methods\n",
    "\n",
    "a.\tDesign some good linguistic features. You can start with basic TFIDF features. Use these classifiers: J48 decision trees, SVMs with linear/RBF kernel, logistic regression, xgboost, random forests and report accuracy on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features...\n",
      "done in 30.619s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf-idf features...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=1000, max_df=0.95, min_df=2, stop_words='english') #USE HELP TO SEE WHAT EACH DOES\n",
    "t0 = time.time()\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train['reviewText'])\n",
    "tfidf_train = pd.DataFrame(tfidf_train.todense(), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_validate = pd.DataFrame(tfidf_vectorizer.transform(validate['reviewText']).todense(), columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_test = pd.DataFrame(tfidf_vectorizer.transform(test['reviewText']).todense(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     10141\n",
      "           2       1.00      1.00      1.00      8226\n",
      "           3       1.00      1.00      1.00     15843\n",
      "           4       1.00      1.00      1.00     27955\n",
      "           5       1.00      1.00      1.00     33274\n",
      "\n",
      "    accuracy                           1.00     95439\n",
      "   macro avg       1.00      1.00      1.00     95439\n",
      "weighted avg       1.00      1.00      1.00     95439\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.38      0.34      1175\n",
      "           2       0.11      0.14      0.12      1039\n",
      "           3       0.21      0.28      0.24      2123\n",
      "           4       0.27      0.44      0.34      4072\n",
      "           5       0.75      0.50      0.60     11035\n",
      "\n",
      "    accuracy                           0.44     19444\n",
      "   macro avg       0.33      0.35      0.33     19444\n",
      "weighted avg       0.53      0.44      0.47     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.38      0.32      1963\n",
      "           2       0.11      0.14      0.13      1799\n",
      "           3       0.18      0.28      0.22      3473\n",
      "           4       0.26      0.44      0.33      7966\n",
      "           5       0.77      0.49      0.60     23687\n",
      "\n",
      "    accuracy                           0.44     38888\n",
      "   macro avg       0.32      0.35      0.32     38888\n",
      "weighted avg       0.56      0.44      0.47     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(tfidf_train, train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(tfidf_train)))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(tfidf_validate)))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(tfidf_test)))\n",
    "\n",
    "# print(\"TRAIN F1_Score: \", f1_score(train.overall, clf.predict(tfidf_train,), average='macro'))\n",
    "# print(\"VALIDATE F1_Score:\", f1_score(validate.overall, clf.predict(tfidf_validate), average='macro'))\n",
    "# print(\"TEST F1_Score: \", f1_score(test.overall, clf.predict(tfidf_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.71      0.63     10141\n",
      "           2       0.44      0.07      0.12      8226\n",
      "           3       0.51      0.32      0.39     15843\n",
      "           4       0.50      0.52      0.51     27955\n",
      "           5       0.62      0.80      0.70     33274\n",
      "\n",
      "    accuracy                           0.57     95439\n",
      "   macro avg       0.53      0.48      0.47     95439\n",
      "weighted avg       0.55      0.57      0.54     95439\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.66      0.57      1175\n",
      "           2       0.36      0.06      0.11      1039\n",
      "           3       0.45      0.28      0.34      2123\n",
      "           4       0.40      0.53      0.45      4072\n",
      "           5       0.79      0.79      0.79     11035\n",
      "\n",
      "    accuracy                           0.63     19444\n",
      "   macro avg       0.50      0.46      0.45     19444\n",
      "weighted avg       0.63      0.63      0.62     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.65      0.57      1963\n",
      "           2       0.35      0.05      0.08      1799\n",
      "           3       0.41      0.26      0.32      3473\n",
      "           4       0.39      0.56      0.46      7966\n",
      "           5       0.81      0.77      0.79     23687\n",
      "\n",
      "    accuracy                           0.64     38888\n",
      "   macro avg       0.50      0.46      0.44     38888\n",
      "weighted avg       0.65      0.64      0.64     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(tfidf_train, train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(tfidf_train)))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(tfidf_validate)))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(tfidf_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.67      0.64     10141\n",
      "           2       0.42      0.16      0.23      8226\n",
      "           3       0.48      0.39      0.43     15843\n",
      "           4       0.51      0.54      0.53     27955\n",
      "           5       0.65      0.76      0.70     33274\n",
      "\n",
      "    accuracy                           0.57     95439\n",
      "   macro avg       0.53      0.50      0.50     95439\n",
      "weighted avg       0.56      0.57      0.56     95439\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.62      0.57      1175\n",
      "           2       0.33      0.13      0.19      1039\n",
      "           3       0.41      0.35      0.38      2123\n",
      "           4       0.39      0.54      0.46      4072\n",
      "           5       0.81      0.75      0.78     11035\n",
      "\n",
      "    accuracy                           0.62     19444\n",
      "   macro avg       0.50      0.48      0.48     19444\n",
      "weighted avg       0.64      0.62      0.63     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.59      0.56      1963\n",
      "           2       0.32      0.12      0.17      1799\n",
      "           3       0.37      0.32      0.34      3473\n",
      "           4       0.38      0.57      0.46      7966\n",
      "           5       0.83      0.74      0.78     23687\n",
      "\n",
      "    accuracy                           0.63     38888\n",
      "   macro avg       0.49      0.47      0.46     38888\n",
      "weighted avg       0.66      0.63      0.64     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(tfidf_train, train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(tfidf_train)))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(tfidf_validate)))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(tfidf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     10141\n",
      "           2       1.00      1.00      1.00      8226\n",
      "           3       1.00      1.00      1.00     15843\n",
      "           4       1.00      1.00      1.00     27955\n",
      "           5       1.00      1.00      1.00     33274\n",
      "\n",
      "    accuracy                           1.00     95439\n",
      "   macro avg       1.00      1.00      1.00     95439\n",
      "weighted avg       1.00      1.00      1.00     95439\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.58      0.54      1175\n",
      "           2       0.39      0.04      0.07      1039\n",
      "           3       0.42      0.24      0.30      2123\n",
      "           4       0.34      0.63      0.44      4072\n",
      "           5       0.81      0.68      0.74     11035\n",
      "\n",
      "    accuracy                           0.58     19444\n",
      "   macro avg       0.49      0.43      0.42     19444\n",
      "weighted avg       0.63      0.58      0.58     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52      1963\n",
      "           2       0.24      0.03      0.05      1799\n",
      "           3       0.39      0.22      0.28      3473\n",
      "           4       0.33      0.66      0.44      7966\n",
      "           5       0.83      0.66      0.73     23687\n",
      "\n",
      "    accuracy                           0.58     38888\n",
      "   macro avg       0.46      0.42      0.40     38888\n",
      "weighted avg       0.64      0.58      0.59     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(tfidf_train, train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(tfidf_train)))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(tfidf_validate)))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(tfidf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train.overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71     10141\n",
      "           2       0.81      0.31      0.44      8226\n",
      "           3       0.68      0.45      0.54     15843\n",
      "           4       0.59      0.64      0.62     27955\n",
      "           5       0.68      0.84      0.75     33274\n",
      "\n",
      "    accuracy                           0.66     95439\n",
      "   macro avg       0.69      0.59      0.61     95439\n",
      "weighted avg       0.67      0.66      0.65     95439\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.56      0.54      1175\n",
      "           2       0.34      0.10      0.15      1039\n",
      "           3       0.43      0.27      0.33      2123\n",
      "           4       0.37      0.57      0.45      4072\n",
      "           5       0.79      0.74      0.77     11035\n",
      "\n",
      "    accuracy                           0.61     19444\n",
      "   macro avg       0.49      0.45      0.45     19444\n",
      "weighted avg       0.63      0.61      0.61     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.55      0.54      1963\n",
      "           2       0.33      0.10      0.15      1799\n",
      "           3       0.39      0.25      0.30      3473\n",
      "           4       0.37      0.60      0.46      7966\n",
      "           5       0.82      0.73      0.77     23687\n",
      "\n",
      "    accuracy                           0.62     38888\n",
      "   macro avg       0.49      0.45      0.44     38888\n",
      "weighted avg       0.65      0.62      0.63     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=42)\n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "train_pred = clf.predict(tfidf_train)\n",
    "train_pred = le.inverse_transform(train_pred)\n",
    "\n",
    "test_pred = clf.predict(tfidf_test)\n",
    "test_pred = le.inverse_transform(test_pred)\n",
    "\n",
    "validate_pred = clf.predict(tfidf_validate)\n",
    "validate_pred = le.inverse_transform(validate_pred)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, train_pred))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, validate_pred))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(tfidf_train, train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(tfidf_train)))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(tfidf_validate)))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(tfidf_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tAverage of word embeddings\n",
    "a.\tLearn word2vec models using gensim on this dataset with the following settings: (a) Size=100, 200, 300, (b) Window=3,7, (c) Min_count=2, 5. Use skipgram.\n",
    "\n",
    "i.\tThis will give 12 word2vec models. For each of these models, for each review take average word embeddings and train a logistic regression. Report accuracy on test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_size = [100, 200, 300]\n",
    "window_size = [3, 7]\n",
    "min_count = [2, 5]\n",
    "#model = gensim.models.Word2Vec(data['processed_text'], size=vector_size, window=window_size, min_count=min_count, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    embeddings = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            embeddings.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    embeddings = np.mean(embeddings, axis = 0)\n",
    "    embeddings = embeddings.tolist()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['embeddings'] = data['processed_text'].apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD EMBEDDING ----- vector_size -  100  window_size -  3  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55     10141\n",
      "           2       0.32      0.05      0.08      8226\n",
      "           3       0.36      0.24      0.29     15843\n",
      "           4       0.41      0.19      0.26     27955\n",
      "           5       0.67      0.93      0.78     73942\n",
      "\n",
      "    accuracy                           0.61    136107\n",
      "   macro avg       0.46      0.39      0.39    136107\n",
      "weighted avg       0.55      0.61      0.56    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53      1175\n",
      "           2       0.39      0.06      0.10      1039\n",
      "           3       0.38      0.25      0.30      2123\n",
      "           4       0.43      0.20      0.27      4072\n",
      "           5       0.69      0.93      0.79     11035\n",
      "\n",
      "    accuracy                           0.63     19444\n",
      "   macro avg       0.48      0.39      0.40     19444\n",
      "weighted avg       0.58      0.63      0.58     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.51      0.52      1963\n",
      "           2       0.34      0.04      0.08      1799\n",
      "           3       0.34      0.21      0.26      3473\n",
      "           4       0.43      0.19      0.26      7966\n",
      "           5       0.71      0.94      0.81     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.47      0.38      0.39     38888\n",
      "weighted avg       0.59      0.66      0.60     38888\n",
      "\n",
      "Took 140.242290 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  100  window_size -  3  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.55      0.55     10141\n",
      "           2       0.33      0.05      0.09      8226\n",
      "           3       0.36      0.24      0.29     15843\n",
      "           4       0.41      0.19      0.26     27955\n",
      "           5       0.68      0.92      0.78     73942\n",
      "\n",
      "    accuracy                           0.61    136107\n",
      "   macro avg       0.46      0.39      0.39    136107\n",
      "weighted avg       0.55      0.61      0.56    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53      1175\n",
      "           2       0.40      0.07      0.11      1039\n",
      "           3       0.38      0.23      0.29      2123\n",
      "           4       0.42      0.21      0.28      4072\n",
      "           5       0.70      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.63     19444\n",
      "   macro avg       0.48      0.40      0.40     19444\n",
      "weighted avg       0.58      0.63      0.58     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.51      0.52      1963\n",
      "           2       0.37      0.05      0.08      1799\n",
      "           3       0.33      0.19      0.24      3473\n",
      "           4       0.42      0.20      0.27      7966\n",
      "           5       0.72      0.93      0.81     23687\n",
      "\n",
      "    accuracy                           0.65     38888\n",
      "   macro avg       0.47      0.38      0.39     38888\n",
      "weighted avg       0.59      0.65      0.60     38888\n",
      "\n",
      "Took 130.591326 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  100  window_size -  7  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.57      0.56     10141\n",
      "           2       0.35      0.06      0.10      8226\n",
      "           3       0.37      0.26      0.31     15843\n",
      "           4       0.42      0.20      0.27     27955\n",
      "           5       0.68      0.93      0.79     73942\n",
      "\n",
      "    accuracy                           0.62    136107\n",
      "   macro avg       0.47      0.40      0.40    136107\n",
      "weighted avg       0.56      0.62      0.56    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.53      1175\n",
      "           2       0.35      0.06      0.10      1039\n",
      "           3       0.39      0.26      0.31      2123\n",
      "           4       0.43      0.21      0.28      4072\n",
      "           5       0.70      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.48      0.40      0.40     19444\n",
      "weighted avg       0.58      0.64      0.58     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.53      1963\n",
      "           2       0.35      0.05      0.08      1799\n",
      "           3       0.35      0.22      0.27      3473\n",
      "           4       0.42      0.19      0.27      7966\n",
      "           5       0.72      0.94      0.81     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.48      0.38      0.39     38888\n",
      "weighted avg       0.60      0.66      0.60     38888\n",
      "\n",
      "Took 193.109672 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  100  window_size -  7  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.56     10141\n",
      "           2       0.35      0.06      0.10      8226\n",
      "           3       0.37      0.26      0.30     15843\n",
      "           4       0.42      0.20      0.27     27955\n",
      "           5       0.68      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.62    136107\n",
      "   macro avg       0.47      0.40      0.40    136107\n",
      "weighted avg       0.56      0.62      0.57    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.54      1175\n",
      "           2       0.40      0.07      0.12      1039\n",
      "           3       0.39      0.25      0.30      2123\n",
      "           4       0.43      0.22      0.29      4072\n",
      "           5       0.70      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.40      0.41     19444\n",
      "weighted avg       0.58      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53      1963\n",
      "           2       0.35      0.05      0.08      1799\n",
      "           3       0.34      0.22      0.27      3473\n",
      "           4       0.42      0.20      0.27      7966\n",
      "           5       0.72      0.94      0.81     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.47      0.38      0.39     38888\n",
      "weighted avg       0.60      0.66      0.61     38888\n",
      "\n",
      "Took 181.067708 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  200  window_size -  3  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.57      0.57     10141\n",
      "           2       0.35      0.08      0.12      8226\n",
      "           3       0.39      0.26      0.31     15843\n",
      "           4       0.43      0.22      0.29     27955\n",
      "           5       0.69      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.62    136107\n",
      "   macro avg       0.48      0.41      0.41    136107\n",
      "weighted avg       0.57      0.62      0.57    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54      1175\n",
      "           2       0.38      0.07      0.12      1039\n",
      "           3       0.38      0.24      0.30      2123\n",
      "           4       0.43      0.22      0.29      4072\n",
      "           5       0.70      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.48      0.40      0.41     19444\n",
      "weighted avg       0.58      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.53      0.54      1963\n",
      "           2       0.38      0.06      0.11      1799\n",
      "           3       0.36      0.21      0.27      3473\n",
      "           4       0.43      0.21      0.29      7966\n",
      "           5       0.72      0.94      0.82     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.49      0.39      0.40     38888\n",
      "weighted avg       0.61      0.66      0.61     38888\n",
      "\n",
      "Took 172.389846 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  200  window_size -  3  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.57      0.57     10141\n",
      "           2       0.35      0.07      0.12      8226\n",
      "           3       0.39      0.26      0.31     15843\n",
      "           4       0.43      0.21      0.28     27955\n",
      "           5       0.69      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.62    136107\n",
      "   macro avg       0.48      0.41      0.41    136107\n",
      "weighted avg       0.57      0.62      0.57    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.55      0.54      1175\n",
      "           2       0.34      0.06      0.10      1039\n",
      "           3       0.39      0.24      0.30      2123\n",
      "           4       0.42      0.23      0.30      4072\n",
      "           5       0.70      0.92      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.48      0.40      0.41     19444\n",
      "weighted avg       0.58      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.53      1963\n",
      "           2       0.35      0.06      0.10      1799\n",
      "           3       0.36      0.22      0.27      3473\n",
      "           4       0.43      0.21      0.28      7966\n",
      "           5       0.72      0.93      0.81     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.48      0.39      0.40     38888\n",
      "weighted avg       0.60      0.66      0.61     38888\n",
      "\n",
      "Took 158.154666 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  200  window_size -  7  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.57      0.57     10141\n",
      "           2       0.36      0.07      0.12      8226\n",
      "           3       0.39      0.27      0.32     15843\n",
      "           4       0.43      0.22      0.29     27955\n",
      "           5       0.69      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.41      0.42    136107\n",
      "weighted avg       0.57      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.54      0.55      1175\n",
      "           2       0.37      0.07      0.12      1039\n",
      "           3       0.39      0.26      0.31      2123\n",
      "           4       0.43      0.24      0.31      4072\n",
      "           5       0.71      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.41      0.42     19444\n",
      "weighted avg       0.59      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54      1963\n",
      "           2       0.35      0.06      0.10      1799\n",
      "           3       0.36      0.22      0.27      3473\n",
      "           4       0.44      0.22      0.29      7966\n",
      "           5       0.73      0.94      0.82     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.49      0.39      0.41     38888\n",
      "weighted avg       0.61      0.66      0.61     38888\n",
      "\n",
      "Took 250.248834 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  200  window_size -  7  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.58      0.57     10141\n",
      "           2       0.35      0.07      0.12      8226\n",
      "           3       0.39      0.27      0.32     15843\n",
      "           4       0.43      0.22      0.29     27955\n",
      "           5       0.69      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.41      0.42    136107\n",
      "weighted avg       0.57      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55      1175\n",
      "           2       0.37      0.07      0.12      1039\n",
      "           3       0.40      0.26      0.31      2123\n",
      "           4       0.43      0.23      0.30      4072\n",
      "           5       0.70      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.41      0.42     19444\n",
      "weighted avg       0.59      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.53      0.54      1963\n",
      "           2       0.36      0.06      0.10      1799\n",
      "           3       0.37      0.22      0.28      3473\n",
      "           4       0.43      0.21      0.28      7966\n",
      "           5       0.72      0.94      0.82     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.49      0.39      0.40     38888\n",
      "weighted avg       0.61      0.66      0.61     38888\n",
      "\n",
      "Took 233.196941 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  300  window_size -  3  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.58      0.57     10141\n",
      "           2       0.35      0.08      0.13      8226\n",
      "           3       0.39      0.28      0.33     15843\n",
      "           4       0.43      0.22      0.29     27955\n",
      "           5       0.69      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.42      0.42    136107\n",
      "weighted avg       0.57      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.55      0.55      1175\n",
      "           2       0.36      0.07      0.12      1039\n",
      "           3       0.39      0.27      0.32      2123\n",
      "           4       0.44      0.23      0.30      4072\n",
      "           5       0.71      0.92      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.41      0.42     19444\n",
      "weighted avg       0.59      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.53      0.54      1963\n",
      "           2       0.37      0.07      0.11      1799\n",
      "           3       0.37      0.24      0.29      3473\n",
      "           4       0.44      0.22      0.29      7966\n",
      "           5       0.73      0.93      0.82     23687\n",
      "\n",
      "    accuracy                           0.67     38888\n",
      "   macro avg       0.49      0.40      0.41     38888\n",
      "weighted avg       0.61      0.67      0.62     38888\n",
      "\n",
      "Took 240.082233 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  300  window_size -  3  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.57      0.57     10141\n",
      "           2       0.36      0.09      0.14      8226\n",
      "           3       0.40      0.27      0.32     15843\n",
      "           4       0.43      0.21      0.29     27955\n",
      "           5       0.69      0.93      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.41      0.42    136107\n",
      "weighted avg       0.57      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55      1175\n",
      "           2       0.37      0.08      0.13      1039\n",
      "           3       0.40      0.26      0.32      2123\n",
      "           4       0.44      0.23      0.30      4072\n",
      "           5       0.71      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.41      0.42     19444\n",
      "weighted avg       0.59      0.64      0.59     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53      1963\n",
      "           2       0.35      0.07      0.12      1799\n",
      "           3       0.37      0.23      0.28      3473\n",
      "           4       0.44      0.21      0.29      7966\n",
      "           5       0.72      0.94      0.82     23687\n",
      "\n",
      "    accuracy                           0.66     38888\n",
      "   macro avg       0.49      0.39      0.41     38888\n",
      "weighted avg       0.61      0.66      0.61     38888\n",
      "\n",
      "Took 225.781942 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  300  window_size -  7  min_count -  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58     10141\n",
      "           2       0.36      0.08      0.13      8226\n",
      "           3       0.40      0.29      0.33     15843\n",
      "           4       0.44      0.23      0.30     27955\n",
      "           5       0.70      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.42      0.43    136107\n",
      "weighted avg       0.58      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.56      0.56      1175\n",
      "           2       0.37      0.08      0.13      1039\n",
      "           3       0.39      0.26      0.31      2123\n",
      "           4       0.44      0.24      0.31      4072\n",
      "           5       0.71      0.93      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.41      0.42     19444\n",
      "weighted avg       0.59      0.64      0.60     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.53      0.54      1963\n",
      "           2       0.36      0.07      0.11      1799\n",
      "           3       0.37      0.23      0.28      3473\n",
      "           4       0.44      0.22      0.30      7966\n",
      "           5       0.73      0.94      0.82     23687\n",
      "\n",
      "    accuracy                           0.67     38888\n",
      "   macro avg       0.49      0.40      0.41     38888\n",
      "weighted avg       0.61      0.67      0.62     38888\n",
      "\n",
      "Took 344.253836 seconds for execution\n",
      " =============================================================\n",
      "WORD EMBEDDING ----- vector_size -  300  window_size -  7  min_count -  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58     10141\n",
      "           2       0.36      0.10      0.15      8226\n",
      "           3       0.40      0.28      0.33     15843\n",
      "           4       0.43      0.24      0.31     27955\n",
      "           5       0.70      0.92      0.79     73942\n",
      "\n",
      "    accuracy                           0.63    136107\n",
      "   macro avg       0.49      0.42      0.43    136107\n",
      "weighted avg       0.58      0.63      0.58    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.57      0.56      1175\n",
      "           2       0.37      0.09      0.14      1039\n",
      "           3       0.40      0.25      0.31      2123\n",
      "           4       0.43      0.25      0.32      4072\n",
      "           5       0.71      0.92      0.80     11035\n",
      "\n",
      "    accuracy                           0.64     19444\n",
      "   macro avg       0.49      0.42      0.43     19444\n",
      "weighted avg       0.59      0.64      0.60     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.53      0.55      1963\n",
      "           2       0.36      0.08      0.13      1799\n",
      "           3       0.38      0.23      0.28      3473\n",
      "           4       0.44      0.24      0.31      7966\n",
      "           5       0.73      0.93      0.82     23687\n",
      "\n",
      "    accuracy                           0.67     38888\n",
      "   macro avg       0.49      0.40      0.42     38888\n",
      "weighted avg       0.62      0.67      0.62     38888\n",
      "\n",
      "Took 318.799761 seconds for execution\n",
      " =============================================================\n"
     ]
    }
   ],
   "source": [
    "for vector in vector_size:\n",
    "    for window in window_size:\n",
    "        for count in min_count:\n",
    "            start = time.time()\n",
    "            print(\"WORD EMBEDDING ----- vector_size - \", vector, \" window_size - \", window, \" min_count - \", count)\n",
    "            model = gensim.models.Word2Vec(data['processed_text'], size=vector, window=window, min_count=count, workers=4,sg=1)\n",
    "            data['embeddings'] = data['processed_text'].apply(get_embeddings)\n",
    "            df3 = data.embeddings.apply(pd.Series)\n",
    "            df3 = df3.fillna(0)\n",
    "            df3['overall'] = data.overall\n",
    "            \n",
    "            train = df3[0:floor(0.7*len(df3))]\n",
    "            validate = df3[floor(0.7*len(df3)):floor(0.8*len(df3))]\n",
    "            test = df3[floor(0.8*len(df3)):]\n",
    "            \n",
    "            clf = LogisticRegression()\n",
    "            clf.fit(train.iloc[:, :vector], train.overall)\n",
    "\n",
    "            print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(train.iloc[:, :vector])))\n",
    "            print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(validate.iloc[:, :vector])))\n",
    "            print(\"TEST: \\n\", classification_report(test.overall, clf.predict(test.iloc[:, :vector])))\n",
    "            \n",
    "            stop = time.time()\n",
    "            duration = stop - start\n",
    "            \n",
    "            print(\"Took %f seconds for execution\\n =============================================================\"%duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\tUse the already available google word2vec model. For each review take average word embeddings and train a logistic regression. Report accuracy on test set. \n",
    "\n",
    "c.\tUse the already available glove models – 50D, 100D and 200D. For each review take average word embeddings and train a logistic regression. Report accuracy on test set for each of the three sized embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(text):\n",
    "    embeddings = []\n",
    "    for word in text:\n",
    "        #print(word)\n",
    "        try:\n",
    "            #print(embeddings_index.get(word))\n",
    "            embeddings.append(embeddings_index.get(word))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    embeddings = [x for x in embeddings if x is not None]\n",
    "    embeddings = np.mean(embeddings, axis = 0)\n",
    "    embeddings = embeddings.tolist()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove 50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open('./Glove_embedding/glove.6B/glove.6B.50d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['embeddings'] = data['processed_text'].apply(get_glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.27      0.33     10141\n",
      "           2       0.24      0.01      0.01      8226\n",
      "           3       0.32      0.07      0.12     15843\n",
      "           4       0.33      0.05      0.08     27955\n",
      "           5       0.58      0.96      0.72     73942\n",
      "\n",
      "    accuracy                           0.56    136107\n",
      "   macro avg       0.38      0.27      0.25    136107\n",
      "weighted avg       0.47      0.56      0.45    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.26      0.32      1175\n",
      "           2       0.17      0.00      0.01      1039\n",
      "           3       0.30      0.06      0.10      2123\n",
      "           4       0.34      0.05      0.09      4072\n",
      "           5       0.60      0.97      0.74     11035\n",
      "\n",
      "    accuracy                           0.58     19444\n",
      "   macro avg       0.37      0.27      0.25     19444\n",
      "weighted avg       0.48      0.58      0.47     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.24      0.31      1963\n",
      "           2       0.29      0.01      0.01      1799\n",
      "           3       0.31      0.06      0.10      3473\n",
      "           4       0.33      0.04      0.07      7966\n",
      "           5       0.64      0.97      0.77     23687\n",
      "\n",
      "    accuracy                           0.62     38888\n",
      "   macro avg       0.39      0.26      0.25     38888\n",
      "weighted avg       0.52      0.62      0.51     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = data.embeddings.apply(pd.Series)\n",
    "df3 = df3.fillna(0)\n",
    "df3['overall'] = data.overall\n",
    "\n",
    "train = df3[0:floor(0.7*len(df3))]\n",
    "validate = df3[floor(0.7*len(df3)):floor(0.8*len(df3))]\n",
    "test = df3[floor(0.8*len(df3)):]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train.iloc[:, :50], train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(train.iloc[:, :50])))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(validate.iloc[:, :50])))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(test.iloc[:, :50])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove 100D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open('./Glove_embedding/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['embeddings'] = data['processed_text'].apply(get_glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.36      0.41     10141\n",
      "           2       0.31      0.01      0.02      8226\n",
      "           3       0.33      0.12      0.18     15843\n",
      "           4       0.37      0.10      0.15     27955\n",
      "           5       0.61      0.94      0.74     73942\n",
      "\n",
      "    accuracy                           0.57    136107\n",
      "   macro avg       0.42      0.31      0.30    136107\n",
      "weighted avg       0.50      0.57      0.49    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.35      0.40      1175\n",
      "           2       0.29      0.01      0.02      1039\n",
      "           3       0.32      0.11      0.16      2123\n",
      "           4       0.39      0.11      0.17      4072\n",
      "           5       0.63      0.95      0.75     11035\n",
      "\n",
      "    accuracy                           0.59     19444\n",
      "   macro avg       0.42      0.31      0.30     19444\n",
      "weighted avg       0.52      0.59      0.51     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.31      0.37      1963\n",
      "           2       0.18      0.01      0.01      1799\n",
      "           3       0.30      0.10      0.14      3473\n",
      "           4       0.37      0.09      0.15      7966\n",
      "           5       0.66      0.95      0.78     23687\n",
      "\n",
      "    accuracy                           0.62     38888\n",
      "   macro avg       0.39      0.29      0.29     38888\n",
      "weighted avg       0.53      0.62      0.53     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = data.embeddings.apply(pd.Series)\n",
    "df3 = df3.fillna(0)\n",
    "df3['overall'] = data.overall\n",
    "\n",
    "train = df3[0:floor(0.7*len(df3))]\n",
    "validate = df3[floor(0.7*len(df3)):floor(0.8*len(df3))]\n",
    "test = df3[floor(0.8*len(df3)):]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train.iloc[:, :100], train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(train.iloc[:, :100])))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(validate.iloc[:, :100])))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(test.iloc[:, :100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove 200D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open('./Glove_embedding/glove.6B/glove.6B.200d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['embeddings'] = data['processed_text'].apply(get_glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.44      0.47     10141\n",
      "           2       0.31      0.03      0.05      8226\n",
      "           3       0.34      0.17      0.22     15843\n",
      "           4       0.39      0.12      0.18     27955\n",
      "           5       0.63      0.93      0.75     73942\n",
      "\n",
      "    accuracy                           0.59    136107\n",
      "   macro avg       0.43      0.34      0.33    136107\n",
      "weighted avg       0.52      0.59      0.51    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.44      0.47      1175\n",
      "           2       0.28      0.02      0.04      1039\n",
      "           3       0.33      0.15      0.21      2123\n",
      "           4       0.41      0.13      0.20      4072\n",
      "           5       0.65      0.94      0.77     11035\n",
      "\n",
      "    accuracy                           0.60     19444\n",
      "   macro avg       0.43      0.34      0.34     19444\n",
      "weighted avg       0.53      0.60      0.53     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.39      0.43      1963\n",
      "           2       0.22      0.02      0.03      1799\n",
      "           3       0.30      0.13      0.18      3473\n",
      "           4       0.40      0.11      0.18      7966\n",
      "           5       0.67      0.95      0.79     23687\n",
      "\n",
      "    accuracy                           0.63     38888\n",
      "   macro avg       0.41      0.32      0.32     38888\n",
      "weighted avg       0.55      0.63      0.55     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = data.embeddings.apply(pd.Series)\n",
    "df3 = df3.fillna(0)\n",
    "df3['overall'] = data.overall\n",
    "\n",
    "train = df3[0:floor(0.7*len(df3))]\n",
    "validate = df3[floor(0.7*len(df3)):floor(0.8*len(df3))]\n",
    "test = df3[floor(0.8*len(df3)):]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train.iloc[:, :200], train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(train.iloc[:, :200])))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(validate.iloc[:, :200])))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(test.iloc[:, :200])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open('./Glove_embedding/glove.6B/glove.6B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['embeddings'] = data['processed_text'].apply(get_glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.47      0.49     10141\n",
      "           2       0.33      0.04      0.08      8226\n",
      "           3       0.35      0.18      0.24     15843\n",
      "           4       0.39      0.14      0.21     27955\n",
      "           5       0.64      0.93      0.76     73942\n",
      "\n",
      "    accuracy                           0.59    136107\n",
      "   macro avg       0.45      0.35      0.35    136107\n",
      "weighted avg       0.53      0.59      0.52    136107\n",
      "\n",
      "VALIDATE: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.46      0.49      1175\n",
      "           2       0.30      0.04      0.07      1039\n",
      "           3       0.33      0.16      0.22      2123\n",
      "           4       0.42      0.15      0.22      4072\n",
      "           5       0.66      0.94      0.77     11035\n",
      "\n",
      "    accuracy                           0.61     19444\n",
      "   macro avg       0.45      0.35      0.36     19444\n",
      "weighted avg       0.54      0.61      0.54     19444\n",
      "\n",
      "TEST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.41      0.45      1963\n",
      "           2       0.24      0.03      0.05      1799\n",
      "           3       0.31      0.15      0.20      3473\n",
      "           4       0.40      0.13      0.19      7966\n",
      "           5       0.68      0.94      0.79     23687\n",
      "\n",
      "    accuracy                           0.64     38888\n",
      "   macro avg       0.43      0.33      0.34     38888\n",
      "weighted avg       0.56      0.64      0.56     38888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = data.embeddings.apply(pd.Series)\n",
    "df3 = df3.fillna(0)\n",
    "df3['overall'] = data.overall\n",
    "\n",
    "train = df3[0:floor(0.7*len(df3))]\n",
    "validate = df3[floor(0.7*len(df3)):floor(0.8*len(df3))]\n",
    "test = df3[floor(0.8*len(df3)):]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train.iloc[:, :300], train.overall)\n",
    "\n",
    "print(\"TRAIN: \\n\", classification_report(train.overall, clf.predict(train.iloc[:, :300])))\n",
    "print(\"VALIDATE: \\n\", classification_report(validate.overall, clf.predict(validate.iloc[:, :300])))\n",
    "print(\"TEST: \\n\", classification_report(test.overall, clf.predict(test.iloc[:, :300])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.108498</td>\n",
       "      <td>-0.029802</td>\n",
       "      <td>-0.046440</td>\n",
       "      <td>0.139854</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>0.167504</td>\n",
       "      <td>-0.079965</td>\n",
       "      <td>-0.084114</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>0.071614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>-0.103794</td>\n",
       "      <td>-0.195137</td>\n",
       "      <td>0.136608</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>-0.020162</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.154162</td>\n",
       "      <td>-0.027610</td>\n",
       "      <td>-0.023393</td>\n",
       "      <td>0.169202</td>\n",
       "      <td>-0.025278</td>\n",
       "      <td>0.175935</td>\n",
       "      <td>-0.067277</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.175852</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054359</td>\n",
       "      <td>-0.105241</td>\n",
       "      <td>-0.150381</td>\n",
       "      <td>0.174147</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>-0.021837</td>\n",
       "      <td>-0.002788</td>\n",
       "      <td>0.089470</td>\n",
       "      <td>-0.039015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175788</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>-0.058356</td>\n",
       "      <td>0.097685</td>\n",
       "      <td>-0.031785</td>\n",
       "      <td>0.131528</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>-0.018782</td>\n",
       "      <td>0.191673</td>\n",
       "      <td>0.054044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053009</td>\n",
       "      <td>-0.012124</td>\n",
       "      <td>-0.085647</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.027499</td>\n",
       "      <td>-0.030120</td>\n",
       "      <td>-0.055209</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.089590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154362</td>\n",
       "      <td>-0.066595</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.069817</td>\n",
       "      <td>-0.056015</td>\n",
       "      <td>0.107302</td>\n",
       "      <td>-0.146141</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>0.143573</td>\n",
       "      <td>0.144131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098437</td>\n",
       "      <td>-0.068592</td>\n",
       "      <td>-0.151323</td>\n",
       "      <td>0.130152</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>-0.061732</td>\n",
       "      <td>-0.022044</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>-0.028356</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>0.101967</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>0.137953</td>\n",
       "      <td>-0.086672</td>\n",
       "      <td>-0.078432</td>\n",
       "      <td>0.083945</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055787</td>\n",
       "      <td>-0.063381</td>\n",
       "      <td>-0.158382</td>\n",
       "      <td>0.121683</td>\n",
       "      <td>0.035825</td>\n",
       "      <td>-0.067687</td>\n",
       "      <td>-0.012062</td>\n",
       "      <td>0.062826</td>\n",
       "      <td>0.023308</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.108498 -0.029802 -0.046440  0.139854 -0.047337  0.167504 -0.079965   \n",
       "1  0.154162 -0.027610 -0.023393  0.169202 -0.025278  0.175935 -0.067277   \n",
       "2  0.175788  0.024813 -0.058356  0.097685 -0.031785  0.131528 -0.098500   \n",
       "3  0.154362 -0.066595  0.001443  0.069817 -0.056015  0.107302 -0.146141   \n",
       "4  0.171910 -0.028356 -0.006452  0.101967 -0.086106  0.137953 -0.086672   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0 -0.084114  0.106931  0.071614  ...  0.005329 -0.103794 -0.195137  0.136608   \n",
       "1  0.007563  0.175852  0.072314  ...  0.054359 -0.105241 -0.150381  0.174147   \n",
       "2 -0.018782  0.191673  0.054044  ...  0.053009 -0.012124 -0.085647  0.056777   \n",
       "3 -0.005836  0.143573  0.144131  ...  0.098437 -0.068592 -0.151323  0.130152   \n",
       "4 -0.078432  0.083945  0.032172  ... -0.055787 -0.063381 -0.158382  0.121683   \n",
       "\n",
       "        295       296       297       298       299  overall  \n",
       "0  0.012111 -0.023665 -0.020162  0.057700  0.024251        4  \n",
       "1  0.037654 -0.021837 -0.002788  0.089470 -0.039015        5  \n",
       "2  0.027499 -0.030120 -0.055209  0.011686 -0.089590        5  \n",
       "3  0.021528 -0.061732 -0.022044  0.029363  0.025114        4  \n",
       "4  0.035825 -0.067687 -0.012062  0.062826  0.023308        5  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "#Create an instance of One-hot-encoder\n",
    "enc=OneHotEncoder()\n",
    "\n",
    "#Passing encoded columns\n",
    "'''\n",
    "NOTE: we have converted the enc.fit_transform() method to array because the fit_transform method\n",
    "of OneHotEncoder returns SpiPy sparse matrix this enables us to save space when we\n",
    "have huge  number of categorical variables\n",
    "'''\n",
    "y_train = enc.fit_transform(train['overall'].values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, :300].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
